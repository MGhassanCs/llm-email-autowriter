# LLM Email Autowriter Configuration

# Environment
ENVIRONMENT=development
DEBUG=true

# vLLM Server Configuration
VLLM_HOST=localhost
VLLM_PORT=8000

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000

# Gradio Configuration
GRADIO_HOST=0.0.0.0
GRADIO_PORT=7860
GRADIO_SHARE=true

# Model Configuration
MODEL_NAME=Qwen/Qwen2.5-7B-Instruct

# HuggingFace Token (optional - set if using private models)
# HF_TOKEN=your_huggingface_token_here

# Logging Configuration
LOG_LEVEL=INFO
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s

# Performance Settings
MAX_CONCURRENT_REQUESTS=10
REQUEST_TIMEOUT=60
